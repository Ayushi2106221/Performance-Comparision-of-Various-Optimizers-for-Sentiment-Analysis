{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\karni\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Download the necessary resources for nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.classify import SklearnClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from textblob import TextBlob, Word\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from subprocess import check_output\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"./Sentiment.csv\")\n",
    "df.head()\n",
    "df['sentiment'].value_counts()\n",
    "df=df[[\"text\",\"sentiment\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[df.sentiment != \"Neutral\"]\n",
    "# df['sentiment']= pd.get_dummies(df['sentiment'], drop_first = True)\n",
    "# df = df.reset_index(drop=True)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How did everyone feel about the Climate Change...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Didn't catch the full GOPdebate last night. He...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.6369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No mention of Tamir Rice and the GOPDebate was...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.3818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>That Carly Fiorina is trending  hours after HE...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GOPDebate  delivered the highest ratings in th...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment   \n",
       "0  How did everyone feel about the Climate Change...   Neutral  \\\n",
       "1  Didn't catch the full GOPdebate last night. He...  Positive   \n",
       "2  No mention of Tamir Rice and the GOPDebate was...   Neutral   \n",
       "3  That Carly Fiorina is trending  hours after HE...  Positive   \n",
       "4  GOPDebate  delivered the highest ratings in th...  Positive   \n",
       "\n",
       "   sentiment_score  \n",
       "0           0.0000  \n",
       "1           0.6369  \n",
       "2           0.3818  \n",
       "3           0.0000  \n",
       "4           0.0000  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleantxt(text):\n",
    "    text= re.sub(r'@[A-Za-z0-9]+', '',text)# removed @mentions\n",
    "    text= re.sub(r'#', '',text)# removed # symbol\n",
    "    text = re.sub(r'RT[\\s]+', '',text)# rmoved RT\n",
    "    text = re.sub(r'https?:\\/\\/\\s+', '',text)# removed the hyperlink\n",
    "    text = re.sub(r':+', '',text)# removed : symbol\n",
    "    text = re.sub(r'--+', '',text)# removed : symbol\n",
    "    text = re.sub(r'http', '',text)\n",
    "    return text\n",
    "df[\"text\"] = df[\"text\"].apply(cleantxt)\n",
    "df[\"text\"] = df[\"text\"].apply(lambda el: el.replace(\"RT \", \"\"))\n",
    "df[\"text\"] = df[\"text\"].apply(lambda el: el.replace(\"#GOPDebate \", \"\"))\n",
    "df[\"text\"] = df[\"text\"].apply(lambda el: el.replace(\"#GOPDebates \", \"\"))\n",
    "df[\"text\"] = df[\"text\"].apply(lambda el: el.replace(\"#GOPdebate \", \"\"))\n",
    "df[\"text\"] = df[\"text\"].apply(lambda el: el.replace(\"#gopdebate \", \"\"))\n",
    "df[\"text\"] = df[\"text\"].str.replace(\"@.+: \",\"\")\n",
    "df[\"text\"] = df[\"text\"].apply(lambda el: el.replace(\"w/ \", \"\"))\n",
    "df[\"text\"] = df[\"text\"].apply(lambda el: el.replace(\"#TedCruz \", \"Ted Cruz \"))\n",
    "df[\"text\"] = df[\"text\"].apply(lambda el: el.replace(\"@realDonaldTrump \", \"Donald Trump \"))\n",
    "df[\"text\"] = df[\"text\"].str.replace(\".+:\\/.+t.co\\/.+\", \"\")\n",
    "df[\"text\"] = df[\"text\"].str.replace(\"(#.+ )|(#.+)\", \"\")\n",
    "df[\"text\"] = df[\"text\"].str.replace(\"@.+ \", \"\")\n",
    "# df[\"text\"] = df[\"text\"].apply(lambda el: replace_emoj(el))\n",
    "df[\"text\"] = df[\"text\"].str.replace(\"[^\\w\\s]\",\"\")\n",
    "df[\"text\"] = df[\"text\"].apply(lambda el: el.strip())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 1 ... 2 0 2]\n"
     ]
    }
   ],
   "source": [
    "X=df['text'].values\n",
    "y=df['sentiment'].values\n",
    "# Encode target labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5040     Positive\n",
      "1078     Positive\n",
      "13717    Positive\n",
      "3527     Positive\n",
      "3404      Neutral\n",
      "           ...   \n",
      "7320      Neutral\n",
      "6017     Negative\n",
      "1374     Negative\n",
      "4785     Negative\n",
      "4058     Positive\n",
      "Name: sentiment, Length: 2775, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Initialize SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to calculate sentiment score for a text using SentimentIntensityAnalyzer\n",
    "def calculate_sentiment(text):\n",
    "    sentiment_score = sid.polarity_scores(text)['compound']\n",
    "    return sentiment_score\n",
    "\n",
    "# Apply sentiment lexicon to the dataset\n",
    "df['sentiment_score'] = df['text'].apply(calculate_sentiment)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['text', 'sentiment_score']], df['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=1000)  # You can adjust max_features as needed\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train['text'])\n",
    "X_test_tfidf = vectorizer.transform(X_test['text'])\n",
    "\n",
    "# Combine TF-IDF features with sentiment scores\n",
    "import scipy.sparse as sp\n",
    "X_train_combined = sp.hstack((X_train_tfidf, X_train['sentiment_score'].values.reshape(-1, 1)))\n",
    "X_test_combined = sp.hstack((X_test_tfidf, X_test['sentiment_score'].values.reshape(-1, 1)))\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J48 Accuracy: 0.62\n",
      "Accuracy for Positive Sentiments: 0.40816326530612246\n",
      "Accuracy for Negative Sentiments: 0.7717770034843205\n",
      "Accuracy for Neutral Sentiments: 0.3480392156862745\n",
      "BFTree Accuracy: 0.62\n",
      "Accuracy for Positive Sentiments: 0.3968253968253968\n",
      "Accuracy for Negative Sentiments: 0.7717770034843205\n",
      "Accuracy for Neutral Sentiments: 0.3660130718954248\n",
      "OneR Accuracy: 0.62\n",
      "Accuracy for Positive Sentiments: 0.0\n",
      "Accuracy for Negative Sentiments: 1.0\n",
      "Accuracy for Neutral Sentiments: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate Decision Tree models\n",
    "# J48 Decision Tree\n",
    "j48_model = DecisionTreeClassifier()  # Default J48 implementation\n",
    "j48_model.fit(X_train_combined, y_train)\n",
    "j48_y_pred = j48_model.predict(X_test_combined)\n",
    "j48_accuracy = accuracy_score(y_test, j48_y_pred)\n",
    "print(f\"J48 Accuracy: {j48_accuracy:.2f}\")\n",
    "positive_mask = (y_test =='Positive')\n",
    "negative_mask = (y_test == 'Negative')\n",
    "neutral_mask = (y_test == 'Neutral')\n",
    "\n",
    "# Calculate accuracy for each sentiment category\n",
    "accuracy_positive = accuracy_score(y_test[positive_mask], j48_y_pred[positive_mask])\n",
    "accuracy_negative = accuracy_score(y_test[negative_mask], j48_y_pred[negative_mask])\n",
    "accuracy_neutral = accuracy_score(y_test[neutral_mask], j48_y_pred[neutral_mask])\n",
    "\n",
    "print(\"Accuracy for Positive Sentiments:\", accuracy_positive)\n",
    "print(\"Accuracy for Negative Sentiments:\", accuracy_negative)\n",
    "print(\"Accuracy for Neutral Sentiments:\", accuracy_neutral)\n",
    "\n",
    "\n",
    "\n",
    "# BFTree (Best-First Decision Tree)\n",
    "bftree_model = DecisionTreeClassifier(splitter='best')  # Best-first decision tree\n",
    "bftree_model.fit(X_train_combined, y_train)\n",
    "bftree_y_pred = bftree_model.predict(X_test_combined)\n",
    "bftree_accuracy = accuracy_score(y_test, bftree_y_pred)\n",
    "print(f\"BFTree Accuracy: {bftree_accuracy:.2f}\")\n",
    "\n",
    "positive_mask = (y_test =='Positive')\n",
    "negative_mask = (y_test == 'Negative')\n",
    "neutral_mask = (y_test == 'Neutral')\n",
    "\n",
    "# Calculate accuracy for each sentiment category\n",
    "accuracy_positive = accuracy_score(y_test[positive_mask], bftree_y_pred[positive_mask])\n",
    "accuracy_negative = accuracy_score(y_test[negative_mask], bftree_y_pred[negative_mask])\n",
    "accuracy_neutral = accuracy_score(y_test[neutral_mask], bftree_y_pred[neutral_mask])\n",
    "\n",
    "print(\"Accuracy for Positive Sentiments:\", accuracy_positive)\n",
    "print(\"Accuracy for Negative Sentiments:\", accuracy_negative)\n",
    "print(\"Accuracy for Neutral Sentiments:\", accuracy_neutral)\n",
    "\n",
    "# OneR Decision Tree\n",
    "oner_model = DecisionTreeClassifier(max_depth=1)  # OneR decision tree (depth limited to 1)\n",
    "oner_model.fit(X_train_combined, y_train)\n",
    "oner_y_pred = oner_model.predict(X_test_combined)\n",
    "oner_accuracy = accuracy_score(y_test, oner_y_pred)\n",
    "print(f\"OneR Accuracy: {oner_accuracy:.2f}\")\n",
    "\n",
    "positive_mask = (y_test =='Positive')\n",
    "negative_mask = (y_test == 'Negative')\n",
    "neutral_mask = (y_test == 'Neutral')\n",
    "\n",
    "# Calculate accuracy for each sentiment category\n",
    "accuracy_positive = accuracy_score(y_test[positive_mask], oner_y_pred[positive_mask])\n",
    "accuracy_negative = accuracy_score(y_test[negative_mask], oner_y_pred[negative_mask])\n",
    "accuracy_neutral = accuracy_score(y_test[neutral_mask], oner_y_pred[neutral_mask])\n",
    "\n",
    "print(\"Accuracy for Positive Sentiments:\", accuracy_positive)\n",
    "print(\"Accuracy for Negative Sentiments:\", accuracy_negative)\n",
    "print(\"Accuracy for Neutral Sentiments:\", accuracy_neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from scipy.optimize import minimize\n",
    "\n",
    "# # Assuming df is your preprocessed DataFrame with 'text' and 'sentiment' columns\n",
    "\n",
    "# # # Splitting data into features (X) and target labels (y)\n",
    "# X = df['text']\n",
    "# y = df['sentiment']\n",
    "\n",
    "# # Splitting data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Tokenization and TF-IDF Vectorization\n",
    "# tfidf_vectorizer = TfidfVectorizer()\n",
    "# X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "# X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# # Define the objective function to optimize\n",
    "# def objective_function(params):\n",
    "#     # Unpack the parameters\n",
    "#     n_estimators, max_depth = params\n",
    "    \n",
    "#     # Initialize and train the Random Forest model with the current parameters\n",
    "#     rf_model = RandomForestClassifier(n_estimators=int(n_estimators), max_depth=int(max_depth), random_state=42)\n",
    "#     rf_model.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "#     # Predict sentiment labels for the test set\n",
    "#     y_pred = rf_model.predict(X_test_tfidf)\n",
    "    \n",
    "#     # Calculate accuracy as the objective to maximize\n",
    "#     accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "#     return -accuracy  # Negative because we want to maximize accuracy\n",
    "\n",
    "# # Initial guess for the parameters\n",
    "# initial_guess = [50, 10]  # Example initial guess for n_estimators and max_depth\n",
    "\n",
    "# # Bounds for the parameters (optional)\n",
    "# bounds = [(10, 100), (2, 20)]  # Example bounds for n_estimators and max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run the optimization using Nelder-Mead algorithm\n",
    "# result = minimize(objective_function, initial_guess, bounds=bounds, method='Nelder-Mead')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print the best parameters found\n",
    "# best_params = result.x\n",
    "# best_accuracy = -result.fun  # Convert back to positive accuracy\n",
    "# print(\"Best Parameters:\", best_params)\n",
    "# print(\"Best Accuracy:\", best_accuracy)\n",
    "\n",
    "# # Train the final Random Forest model with the best parameters\n",
    "# best_n_estimators, best_max_depth = best_params\n",
    "# final_dt_model = DecisionTreeClassifier(max_depth=int(best_max_depth), random_state=42)\n",
    "# final_dt_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# # Evaluate the final model on the test set\n",
    "# y_pred_final = final_dt_model.predict(X_test_tfidf)\n",
    "# final_accuracy = accuracy_score(y_test, y_pred_final)\n",
    "# print(\"Final Accuracy:\", final_accuracy)\n",
    "\n",
    "\n",
    "# # final_rf_model = RandomForestClassifier(n_estimators=int(best_n_estimators), max_depth=int(best_max_depth), random_state=42)\n",
    "# # final_rf_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# # # Evaluate the final model on the test set\n",
    "# # y_pred_final = final_rf_model.predict(X_test_tfidf)\n",
    "# # final_accuracy = accuracy_score(y_test, y_pred_final)\n",
    "# # print(\"Final Accuracy:\", final_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost as xgb\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Tokenization and TF-IDF Vectorization\n",
    "# tfidf_vectorizer = TfidfVectorizer()\n",
    "# X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "# X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# # Define the XGBoost model\n",
    "# xgb_model = xgb.XGBClassifier(\n",
    "#     objective='multi:relu',  # for multiclass classification\n",
    "#     num_class=len(np.unique(y)),  # number of classes\n",
    "#     max_depth=8,  # example depth, tune this parameter\n",
    "#     learning_rate=0.1,  # example learning rate, tune this parameter\n",
    "#     n_estimators=500,  # number of trees, tune this parameter\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# # Train the XGBoost model\n",
    "# xgb_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# # Predict sentiment labels for the test set\n",
    "# y_pred = xgb_model.predict(X_test_tfidf)\n",
    "\n",
    "# # Calculate accuracy\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: [10.          0.01528267]\n",
      "Best Accuracy: 0.6539293439077145\n",
      "Final Accuracy: 0.6457657657657657\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def objective_function(params):\n",
    "    \"\"\"Objective function to optimize. Takes a list of hyperparameters as input.\"\"\"\n",
    "    C, gamma = params\n",
    "    \n",
    "    # Initialize the SVM model with the given hyperparameters\n",
    "    model = SVC(C=C, gamma=gamma)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_preprocessed, y_train)\n",
    "    \n",
    "    # Evaluate the model on the validation set\n",
    "    y_pred = model.predict(X_valid_preprocessed)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_valid, y_pred)\n",
    "    \n",
    "    return -accuracy  # Minimize negative accuracy\n",
    "\n",
    "def tlbo(objective_function, bounds, population_size=10, max_generations=100):\n",
    "    \"\"\"Teaching-Learning-Based Optimization (TLBO) algorithm.\"\"\"\n",
    "    num_dimensions = len(bounds)\n",
    "    population = np.random.uniform(bounds[:, 0], bounds[:, 1], (population_size, num_dimensions))\n",
    "    \n",
    "    for generation in range(max_generations):\n",
    "        # Evaluate the fitness of each solution\n",
    "        fitness = np.array([objective_function(individual) for individual in population])\n",
    "        \n",
    "        # Find the best solution (teacher)\n",
    "        teacher_index = np.argmin(fitness)\n",
    "        teacher = population[teacher_index]\n",
    "        \n",
    "        # Teacher phase\n",
    "        for i in range(population_size):\n",
    "            population[i] += np.random.uniform(-1, 1, num_dimensions) * (teacher - population[i])\n",
    "        \n",
    "        # Learner phase\n",
    "        for i in range(population_size):\n",
    "            peer_index = np.random.choice([j for j in range(population_size) if j != i])\n",
    "            peer = population[peer_index]\n",
    "            population[i] += np.random.uniform(-1, 1, num_dimensions) * (peer - population[i])\n",
    "        \n",
    "        # Clip solutions to the bounds\n",
    "        population = np.clip(population, bounds[:, 0], bounds[:, 1])\n",
    "    \n",
    "    # Return the best solution found\n",
    "    best_index = np.argmin(fitness)\n",
    "    best_solution = population[best_index]\n",
    "    best_fitness = fitness[best_index]\n",
    "    \n",
    "    return best_solution, best_fitness\n",
    "\n",
    "# Assuming df is your preprocessed DataFrame with 'text' and 'sentiment' columns\n",
    "\n",
    "# Splitting data into features (X) and target labels (y)\n",
    "X = df['text']\n",
    "y = df['sentiment']\n",
    "\n",
    "# Splitting data into training, validation, and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "# Create a preprocessing pipeline\n",
    "preprocessing_pipeline = make_pipeline(\n",
    "    TfidfVectorizer(),\n",
    "    StandardScaler(with_mean=False)  # Assuming sparse input, no need to center\n",
    ")\n",
    "\n",
    "# Preprocess the training and validation data\n",
    "X_train_preprocessed = preprocessing_pipeline.fit_transform(X_train)\n",
    "X_valid_preprocessed = preprocessing_pipeline.transform(X_valid)\n",
    "\n",
    "# Define the search space for hyperparameters\n",
    "search_space = np.array([(0.1, 10),   # C\n",
    "                         (0.01, 1)])  # gamma\n",
    "\n",
    "# Run TLBO to optimize hyperparameters\n",
    "best_params, best_fitness = tlbo(objective_function, search_space)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Accuracy:\", -best_fitness)  # Convert back to positive accuracy\n",
    "\n",
    "# Train the final SVM model with the best parameters\n",
    "C, gamma = best_params\n",
    "final_model = SVC(C=C, gamma=gamma)\n",
    "final_model.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "# Evaluate the final model on the test set\n",
    "X_test_preprocessed = preprocessing_pipeline.transform(X_test)\n",
    "y_pred_final = final_model.predict(X_test_preprocessed)\n",
    "final_accuracy = accuracy_score(y_test, y_pred_final)\n",
    "print(\"Final Accuracy:\", final_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize SentimentIntensityAnalyzer\n",
    "# sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# # Function to calculate sentiment score for a text using SentimentIntensityAnalyzer\n",
    "# def calculate_sentiment(text):\n",
    "#     sentiment_score = sid.polarity_scores(text)['compound']\n",
    "#     return sentiment_score\n",
    "\n",
    "# # Apply sentiment lexicon to the dataset\n",
    "# df['sentiment_score'] = df['text'].apply(calculate_sentiment)\n",
    "\n",
    "# # Split the dataset into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(df[['text', 'sentiment_score']], df['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "# vectorizer = TfidfVectorizer(max_features=1000)  # You can adjust max_features as needed\n",
    "# X_train_tfidf = vectorizer.fit_transform(X_train['text'])\n",
    "# X_test_tfidf = vectorizer.transform(X_test['text'])\n",
    "\n",
    "# # Combine TF-IDF features with sentiment scores\n",
    "# import scipy.sparse as sp\n",
    "# X_train_combined = sp.hstack((X_train_tfidf, X_train['sentiment_score'].values.reshape(-1, 1)))\n",
    "# X_test_combined = sp.hstack((X_test_tfidf, X_test['sentiment_score'].values.reshape(-1, 1)))\n",
    "\n",
    "# # Train and evaluate Decision Tree models\n",
    "# # J48 Decision Tree\n",
    "# j48_model = DecisionTreeClassifier()  # Default J48 implementation\n",
    "# j48_model.fit(X_train_combined, y_train)\n",
    "# j48_y_pred = j48_model.predict(X_test_combined)\n",
    "# j48_accuracy = accuracy_score(y_test, j48_y_pred)\n",
    "# print(f\"J48 Accuracy: {j48_accuracy:.2f}\")\n",
    "\n",
    "# # BFTree (Best-First Decision Tree)\n",
    "# bftree_model = DecisionTreeClassifier(splitter='best')  # Best-first decision tree\n",
    "# bftree_model.fit(X_train_combined, y_train)\n",
    "# bftree_y_pred = bftree_model.predict(X_test_combined)\n",
    "# bftree_accuracy = accuracy_score(y_test, bftree_y_pred)\n",
    "# print(f\"BFTree Accuracy: {bftree_accuracy:.2f}\")\n",
    "\n",
    "# # OneR Decision Tree\n",
    "# oner_model = DecisionTreeClassifier(max_depth=1)  # OneR decision tree (depth limited to 1)\n",
    "# oner_model.fit(X_train_combined, y_train)\n",
    "# oner_y_pred = oner_model.predict(X_test_combined)\n",
    "# oner_accuracy = accuracy_score(y_test, oner_y_pred)\n",
    "# print(f\"OneR Accuracy: {oner_accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
