{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.classify import SklearnClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from textblob import TextBlob, Word\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from subprocess import check_output\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "Negative    8493\n",
       "Neutral     3142\n",
       "Positive    2236\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"./Sentiment.csv\")\n",
    "df.head()\n",
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices_to_drop = df[df['sentiment'] == 'Negative'].index[1::5]\n",
    "\n",
    "# # Drop rows with the obtained indices\n",
    "# df.drop(indices_to_drop, inplace=True)\n",
    "\n",
    "# # Reset the index after dropping rows\n",
    "# df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>candidate</th>\n",
       "      <th>candidate_confidence</th>\n",
       "      <th>relevant_yn</th>\n",
       "      <th>relevant_yn_confidence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_confidence</th>\n",
       "      <th>subject_matter</th>\n",
       "      <th>subject_matter_confidence</th>\n",
       "      <th>candidate_gold</th>\n",
       "      <th>...</th>\n",
       "      <th>relevant_yn_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>sentiment_gold</th>\n",
       "      <th>subject_matter_gold</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.6578</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @NancyLeeGrahn: How did everyone feel about...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:46 -0700</td>\n",
       "      <td>629697200650592256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Scott Walker</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:46 -0700</td>\n",
       "      <td>629697199560069120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.6629</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>0.6629</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @TJMShow: No mention of Tamir Rice and the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:46 -0700</td>\n",
       "      <td>629697199312482304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>0.7039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:45 -0700</td>\n",
       "      <td>629697197118861312</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.7045</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:45 -0700</td>\n",
       "      <td>629697196967903232</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id               candidate  candidate_confidence relevant_yn   \n",
       "0   1  No candidate mentioned                   1.0         yes  \\\n",
       "1   2            Scott Walker                   1.0         yes   \n",
       "2   3  No candidate mentioned                   1.0         yes   \n",
       "3   4  No candidate mentioned                   1.0         yes   \n",
       "4   5            Donald Trump                   1.0         yes   \n",
       "\n",
       "   relevant_yn_confidence sentiment  sentiment_confidence     subject_matter   \n",
       "0                     1.0   Neutral                0.6578  None of the above  \\\n",
       "1                     1.0  Positive                0.6333  None of the above   \n",
       "2                     1.0   Neutral                0.6629  None of the above   \n",
       "3                     1.0  Positive                1.0000  None of the above   \n",
       "4                     1.0  Positive                0.7045  None of the above   \n",
       "\n",
       "   subject_matter_confidence candidate_gold  ... relevant_yn_gold   \n",
       "0                     1.0000            NaN  ...              NaN  \\\n",
       "1                     1.0000            NaN  ...              NaN   \n",
       "2                     0.6629            NaN  ...              NaN   \n",
       "3                     0.7039            NaN  ...              NaN   \n",
       "4                     1.0000            NaN  ...              NaN   \n",
       "\n",
       "  retweet_count  sentiment_gold subject_matter_gold   \n",
       "0             5             NaN                 NaN  \\\n",
       "1            26             NaN                 NaN   \n",
       "2            27             NaN                 NaN   \n",
       "3           138             NaN                 NaN   \n",
       "4           156             NaN                 NaN   \n",
       "\n",
       "                                                text tweet_coord   \n",
       "0  RT @NancyLeeGrahn: How did everyone feel about...         NaN  \\\n",
       "1  RT @ScottWalker: Didn't catch the full #GOPdeb...         NaN   \n",
       "2  RT @TJMShow: No mention of Tamir Rice and the ...         NaN   \n",
       "3  RT @RobGeorge: That Carly Fiorina is trending ...         NaN   \n",
       "4  RT @DanScavino: #GOPDebate w/ @realDonaldTrump...         NaN   \n",
       "\n",
       "               tweet_created            tweet_id  tweet_location   \n",
       "0  2015-08-07 09:54:46 -0700  629697200650592256             NaN  \\\n",
       "1  2015-08-07 09:54:46 -0700  629697199560069120             NaN   \n",
       "2  2015-08-07 09:54:46 -0700  629697199312482304             NaN   \n",
       "3  2015-08-07 09:54:45 -0700  629697197118861312           Texas   \n",
       "4  2015-08-07 09:54:45 -0700  629697196967903232             NaN   \n",
       "\n",
       "                user_timezone  \n",
       "0                       Quito  \n",
       "1                         NaN  \n",
       "2                         NaN  \n",
       "3  Central Time (US & Canada)  \n",
       "4                     Arizona  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "Negative    8493\n",
       "Neutral     3142\n",
       "Positive    2236\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13871, 21)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13871, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df[[\"text\",\"sentiment\"]]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>RT @BBCJonSopel: In midst of #GOPDebate came b...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7289</th>\n",
       "      <td>RT @tarynoneill: THERE WAS NOT ONE QUESTION ON...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10450</th>\n",
       "      <td>They were lynching Black folks in \"Jesus Name\"...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11209</th>\n",
       "      <td>RT @RWSurferGirl: Fox is cherry picking the ca...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>Marco Rubio debating like a champ. #partyofthe...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text sentiment\n",
       "331    RT @BBCJonSopel: In midst of #GOPDebate came b...   Neutral\n",
       "7289   RT @tarynoneill: THERE WAS NOT ONE QUESTION ON...  Negative\n",
       "10450  They were lynching Black folks in \"Jesus Name\"...  Negative\n",
       "11209  RT @RWSurferGirl: Fox is cherry picking the ca...  Negative\n",
       "1454   Marco Rubio debating like a champ. #partyofthe...  Positive"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[df.sentiment != \"Neutral\"]\n",
    "# df['sentiment']= pd.get_dummies(df['sentiment'], drop_first = True)\n",
    "# df = df.reset_index(drop=True)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4927</th>\n",
       "      <td>What point ding-bat \"commentary\" GOPDebate?</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13427</th>\n",
       "      <td>While Ted Cruz speaking, America parent tryin'...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5334</th>\n",
       "      <td>Vets politician's afterthoughts. Squeaky wheel...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12187</th>\n",
       "      <td>The candidate attack Fox stoping speaking. ðŸ‡ºðŸ‡¸ ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12463</th>\n",
       "      <td>Jed bush win presidency mean get hilarious sho...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8282</th>\n",
       "      <td>Two great debates! Who favorites? Let know tho...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11660</th>\n",
       "      <td>Same mistake Republicans always made, still ma...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11188</th>\n",
       "      <td>Why chant \"war\" together? GOPdebates republica...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10433</th>\n",
       "      <td>_f Does God super PAC? GOPDebates</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10855</th>\n",
       "      <td>Finally question Cruz. Iranian deal terrible R...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text sentiment\n",
       "4927         What point ding-bat \"commentary\" GOPDebate?  Negative\n",
       "13427  While Ted Cruz speaking, America parent tryin'...  Negative\n",
       "5334   Vets politician's afterthoughts. Squeaky wheel...   Neutral\n",
       "12187  The candidate attack Fox stoping speaking. ðŸ‡ºðŸ‡¸ ...  Negative\n",
       "12463  Jed bush win presidency mean get hilarious sho...  Negative\n",
       "8282   Two great debates! Who favorites? Let know tho...  Positive\n",
       "11660  Same mistake Republicans always made, still ma...  Negative\n",
       "11188  Why chant \"war\" together? GOPdebates republica...  Negative\n",
       "10433                  _f Does God super PAC? GOPDebates   Neutral\n",
       "10855  Finally question Cruz. Iranian deal terrible R...  Negative"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleantxt(text):\n",
    "    text= re.sub(r'@[A-Za-z0-9]+', '',text)# removed @mentions\n",
    "    text= re.sub(r'#', '',text)# removed # symbol\n",
    "    text = re.sub(r'RT[\\s]+', '',text)# rmoved RT\n",
    "    text = re.sub(r'https?:\\/\\/\\s+', '',text)# removed the hyperlink\n",
    "    text = re.sub(r':+', '',text)# removed : symbol\n",
    "    text = re.sub(r'--+', '',text)# removed : symbol\n",
    "    text = re.sub(r'http', '',text)\n",
    "    return text\n",
    "df[\"text\"] = df[\"text\"].apply(cleantxt)\n",
    "df[\"text\"] = df[\"text\"].apply(lambda el: el.replace(\"RT \", \"\"))\n",
    "df[\"text\"] = df[\"text\"].apply(lambda el: el.replace(\"GOPDebate \", \"\"))\n",
    "df[\"text\"] = df[\"text\"].apply(lambda el: el.replace(\"GOPDebates \", \"\"))\n",
    "df[\"text\"] = df[\"text\"].apply(lambda el: el.replace(\"GOPdebate \", \"\"))\n",
    "df[\"text\"] = df[\"text\"].apply(lambda el: el.replace(\"gopdebate \", \"\"))\n",
    "df[\"text\"] = df[\"text\"].str.replace(\"@.+: \",\"\")\n",
    "df[\"text\"] = df[\"text\"].apply(lambda el: el.replace(\"w/ \", \"\"))\n",
    "df[\"text\"] = df[\"text\"].apply(lambda el: el.replace(\"TedCruz \", \"Ted Cruz \"))\n",
    "df[\"text\"] = df[\"text\"].apply(lambda el: el.replace(\"@realDonaldTrump \", \"Donald Trump \"))\n",
    "df[\"text\"] = df[\"text\"].str.replace(\".+:\\/.+t.co\\/.+\", \"\")\n",
    "df[\"text\"] = df[\"text\"].str.replace(\"(#.+ )|(#.+)\", \"\")\n",
    "df[\"text\"] = df[\"text\"].str.replace(\"@.+ \", \"\")\n",
    "# df[\"text\"] = df[\"text\"].apply(lambda el: replace_emoj(el))\n",
    "df[\"text\"] = df[\"text\"].str.replace(\"[^\\w\\s]\",\"\")\n",
    "df[\"text\"] = df[\"text\"].apply(lambda el: el.strip())\n",
    "df[\"text\"] = df[\"text\"].apply(lambda el: \" \".join(el for el in el.split() if el not in nltk.corpus.stopwords.words(\"english\")))\n",
    "# df[\"text\"] = df[\"text\"].apply(lambda el: \" \".join([str(TextBlob(e).correct()) for e in el.split()]))\n",
    "df[\"text\"] = df[\"text\"].apply(lambda el: \" \".join([Word(e).lemmatize() for e in el.split()]))\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ///////////////////////////////////////////////////////////////////\n",
    "# from nrclex import NRCLex\n",
    "# # df=df[\"text\"]\n",
    "# df['emotion']=df['text'].apply(lambda x: NRCLex(x).affect_frequencies)\n",
    "# df=pd.concat([df.drop(['emotion'],axis=1),df['emotion'].apply(pd.Series)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df['text'].values\n",
    "y=df['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Breaking Brian Williams handed Chris Christie donut calm down. ðŸ‡ºðŸ‡¸ GOPDebates'\n",
      " \"Most air time last night THE FOX MODERATORS GOPDebate Really? Why would make see fake ? That's nasty.\"\n",
      " 'Jeb Bush Im prolife others Schiavo. GOPdebates' ...\n",
      " 'slaying //t.co/sLFVbkScmS'\n",
      " \"Not Carson disqualified, I'm sure I'd go I brain tumor GOPDebates\"\n",
      " 'Reps r like minions, searching 4 guy act evil 2 make boss. could learn movie.']\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=50)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=TfidfVectorizer()\n",
    "X_train=vectorizer.fit_transform(X_train)\n",
    "X_test=vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Accuracy 0.7947909156452776\n"
     ]
    }
   ],
   "source": [
    "#accuracy score on the training data\n",
    "X_train_pred=model.predict(X_train)\n",
    "train_data_acc=accuracy_score(y_train,X_train_pred)\n",
    "print(\"Training Data Accuracy\",train_data_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy score on the testing data\n",
    "X_test_pred=model.predict(X_test)\n",
    "test_data_acc=accuracy_score(y_test,X_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Data Accuracy 0.6965765765765766\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing Data Accuracy\",test_data_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.73      0.90      0.80      1719\n",
      "     Neutral       0.54      0.32      0.40       611\n",
      "    Positive       0.67      0.42      0.51       445\n",
      "\n",
      "    accuracy                           0.70      2775\n",
      "   macro avg       0.65      0.55      0.57      2775\n",
      "weighted avg       0.68      0.70      0.67      2775\n",
      "\n",
      "['Negative' 'Negative' 'Neutral' ... 'Positive' 'Negative' 'Negative']\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, X_test_pred))\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Positive Sentiments: 0.41797752808988764\n",
      "Accuracy for Negative Sentiments: 0.9028504944735312\n",
      "Accuracy for Neutral Sentiments: 0.3191489361702128\n"
     ]
    }
   ],
   "source": [
    "positive_mask = (y_test =='Positive')\n",
    "negative_mask = (y_test == 'Negative')\n",
    "neutral_mask = (y_test == 'Neutral')\n",
    "\n",
    "# Calculate accuracy for each sentiment category\n",
    "accuracy_positive = accuracy_score(y_test[positive_mask], X_test_pred[positive_mask])\n",
    "accuracy_negative = accuracy_score(y_test[negative_mask], X_test_pred[negative_mask])\n",
    "accuracy_neutral = accuracy_score(y_test[neutral_mask], X_test_pred[neutral_mask])\n",
    "\n",
    "print(\"Accuracy for Positive Sentiments:\", accuracy_positive)\n",
    "print(\"Accuracy for Negative Sentiments:\", accuracy_negative)\n",
    "print(\"Accuracy for Neutral Sentiments:\", accuracy_neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # here i am creating function to get subjectivity\n",
    "# def getSubjectivity(text):\n",
    "#     return TextBlob(text).sentiment.subjectivity\n",
    "# # here i am creating function to get polarity\n",
    "# def getPolarity(text):\n",
    "#     return TextBlob(text).sentiment.polarity\n",
    "# # here i am creating two new column of subjectivity and polarity\n",
    "# df[\"subjectivity\"] = df[\"text\"].apply(getSubjectivity)\n",
    "# df[\"polarity\"] = df[\"text\"].apply(getPolarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allwords = ' '.join([twts for twts in df[\"text\"]])\n",
    "# wordcloud = WordCloud(width=2500,\n",
    "#                       height=2000,stopwords=STOPWORDS,background_color=\"white\",random_state=21\n",
    "#                      ).generate(allwords)\n",
    "# plt.figure(1,figsize=(10,10))\n",
    "# plt.imshow(wordcloud)\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #training set after doing visualisation\n",
    "# text = []\n",
    "# stopwords_set = set(stopwords.words(\"english\"))\n",
    "\n",
    "# for index, row in df.iterrows():\n",
    "#     words_filtered = [e.lower() for e in row.text.split() if len(e) >= 3]\n",
    "#     words_cleaned = [word for word in words_filtered\n",
    "#         if 'http' not in word\n",
    "#         and not word.startswith('@')\n",
    "#         and not word.startswith('#')\n",
    "#         and word != 'RT']\n",
    "#     words_without_stopwords = [word for word in words_cleaned if not word in stopwords_set]\n",
    "#     text.append((words_without_stopwords, row.sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=50)\n",
    "# print(X_test)\n",
    "# vectorizer=TfidfVectorizer()\n",
    "# X_train=vectorizer.fit_transform(X_train)\n",
    "# X_test=vectorizer.transform(X_test)\n",
    "# model=LogisticRegression(max_iter=1000)\n",
    "# model.fit(X_train,y_train)\n",
    "# #accuracy score on the training data\n",
    "# X_train_pred=model.predict(X_train)\n",
    "# train_data_acc=accuracy_score(y_train,X_train_pred)\n",
    "# print(\"Training Data Accuracy\",train_data_acc)\n",
    "# #accuracy score on the testing data\n",
    "# X_test_pred=model.predict(X_test)\n",
    "# test_data_acc=accuracy_score(y_test,X_test_pred)\n",
    "# print(\"Testing Data Accuracy\",test_data_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
